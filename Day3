# ğŸš€ Databricks 14 Days AI Challenge
### #DatabricksWithIDC

---

## ğŸ“… DAY 3 (11/01/26) â€“ PySpark Transformations Deep Dive

Completed **Day 3** of the Databricks 14 Days AI Challenge with a deep dive into **advanced PySpark transformations**, joins, window functions, and feature engineering.

---

### ğŸ“˜ What I Learned
- Comparison of **PySpark vs Pandas** for large-scale data processing
- Different types of joins:
  - Inner
  - Left
  - Right
  - Outer
- **Window functions** for running totals and rankings
- **User-Defined Functions (UDFs)** for custom transformations

---

### ğŸ› ï¸ Tasks Completed
- Loaded the full e-commerce dataset
- Performed complex joins across datasets
- Calculated running totals using window functions
- Created derived features for analytical use cases

---

### ğŸ“ Practice (PySpark)

```python
from pyspark.sql import functions as F
from pyspark.sql.window import Window

# Top 5 products by revenue
revenue = events.filter(F.col("event_type") == "purchase") \
    .groupBy("product_id", "product_name") \
    .agg(F.sum("price").alias("revenue")) \
    .orderBy(F.desc("revenue")).limit(5)

# Running total per user
window = Window.partitionBy("user_id").orderBy("event_time")
events.withColumn("cumulative_events", F.count("*").over(window))

# Conversion rate by category
events.groupBy("category_code", "event_type").count() \
    .pivot("event_type").sum("count") \
    .withColumn(
        "conversion_rate",
        (F.col("purchase") / F.col("view")) * 100
    )
ğŸ™ Acknowledgements
Grateful for the initiative and learning support by:

Databricks
Codebasics
Indian Data Club
#DatabricksWithIDC

ğŸ™ Credits:
Databricks | Codebasics | Indian Data Club

#DatabricksWithIDC #LearningInPublic #DataEngineering #Indian Data Club
